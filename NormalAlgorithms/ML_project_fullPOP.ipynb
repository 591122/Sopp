{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import random\n",
    "import metoder\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#path:\n",
    "#file_path = r\"C:\\Users\\vikto\\Documents\\Skole\\Datadrevne_systemer\\ML_Project\\glass_data-4_lev.csv\"\n",
    "file_path = \"../Datasett/mushrooms.csv\"\n",
    "#importing file and print how the structure of data were inported. \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define a mapping dictionary\n",
    "#type_mapping = {'T1': 0, 'T2': 1, 'T3': 2, 'T4': 3, 'T5': 4, 'T6': 5}\n",
    "\n",
    "# Apply the mapping to the 'Type' column\n",
    "#df['Type'] = df['Type'].map(type_mapping)\n",
    "\n",
    "#drop ID number\n",
    "#df = df.drop(columns=['Id'])\n",
    "\n",
    "# Verify the 'Type' column is now of type int64\n",
    "print(df['class'].dtype)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small exploration of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique rows:  8124\n"
     ]
    }
   ],
   "source": [
    "unique_rows = df.drop_duplicates()\n",
    "\n",
    "\n",
    "num_unique_rows = unique_rows.shape[0]\n",
    "\n",
    "print(\"Number of unique rows: \", num_unique_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique rows: 8124\n"
     ]
    }
   ],
   "source": [
    "# Check the number of unique rows in the DataFrame\n",
    "num_unique_rows = df.drop_duplicates().shape[0]\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique rows:\", num_unique_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set clearly shows that T1, T2 is most frequently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram of age with hue for income\n",
    "sns.histplot(data=df, x='cap-shape', hue='class', multiple='stack', palette='pastel')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('cap shape')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('cap shape Distribution by class')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df.columns[:-1]:  # Exclude the 'Type' column\n",
    " #   sns.boxplot(x='Type', y=col, data=df)\n",
    "  #  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding to ensure the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class  cap-shape_b  cap-shape_c  cap-shape_f  cap-shape_k  cap-shape_s  \\\n",
      "0         1            0            0            0            0            0   \n",
      "1         0            0            0            0            0            0   \n",
      "2         0            1            0            0            0            0   \n",
      "3         1            0            0            0            0            0   \n",
      "4         0            0            0            0            0            0   \n",
      "...     ...          ...          ...          ...          ...          ...   \n",
      "8119      0            0            0            0            1            0   \n",
      "8120      0            0            0            0            0            0   \n",
      "8121      0            0            0            1            0            0   \n",
      "8122      1            0            0            0            1            0   \n",
      "8123      0            0            0            0            0            0   \n",
      "\n",
      "      cap-shape_x  cap-surface_f  cap-surface_g  cap-surface_s  ...  \\\n",
      "0               1              0              0              1  ...   \n",
      "1               1              0              0              1  ...   \n",
      "2               0              0              0              1  ...   \n",
      "3               1              0              0              0  ...   \n",
      "4               1              0              0              1  ...   \n",
      "...           ...            ...            ...            ...  ...   \n",
      "8119            0              0              0              1  ...   \n",
      "8120            1              0              0              1  ...   \n",
      "8121            0              0              0              1  ...   \n",
      "8122            0              0              0              0  ...   \n",
      "8123            1              0              0              1  ...   \n",
      "\n",
      "      population_s  population_v  population_y  habitat_d  habitat_g  \\\n",
      "0                1             0             0          0          0   \n",
      "1                0             0             0          0          1   \n",
      "2                0             0             0          0          0   \n",
      "3                1             0             0          0          0   \n",
      "4                0             0             0          0          1   \n",
      "...            ...           ...           ...        ...        ...   \n",
      "8119             0             0             0          0          0   \n",
      "8120             0             1             0          0          0   \n",
      "8121             0             0             0          0          0   \n",
      "8122             0             1             0          0          0   \n",
      "8123             0             0             0          0          0   \n",
      "\n",
      "      habitat_l  habitat_m  habitat_p  habitat_u  habitat_w  \n",
      "0             0          0          0          1          0  \n",
      "1             0          0          0          0          0  \n",
      "2             0          1          0          0          0  \n",
      "3             0          0          0          1          0  \n",
      "4             0          0          0          0          0  \n",
      "...         ...        ...        ...        ...        ...  \n",
      "8119          1          0          0          0          0  \n",
      "8120          1          0          0          0          0  \n",
      "8121          1          0          0          0          0  \n",
      "8122          1          0          0          0          0  \n",
      "8123          1          0          0          0          0  \n",
      "\n",
      "[8124 rows x 118 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Perform one-hot encoding for all categorical columns except the \"class\" column\n",
    "df_encoded = pd.get_dummies(df, columns=[\"cap-shape\",\"cap-surface\",\"cap-color\",\"bruises\",\"odor\",\"gill-attachment\",\"gill-spacing\",\"gill-size\",\"gill-color\",\"stalk-shape\",\"stalk-root\",\"stalk-surface-above-ring\",\"stalk-surface-below-ring\",\"stalk-color-above-ring\",\"stalk-color-below-ring\",\"veil-type\",\"veil-color\",\"ring-number\",\"ring-type\",\"spore-print-color\",\"population\",\"habitat\"])\n",
    "\n",
    "# You can also encode the target variable \"class\" if needed\n",
    "# class_encoded = pd.get_dummies(df[\"class\"], prefix=\"class\")\n",
    "\n",
    "# Replace \"p\" with 1 and \"e\" with 0 in the \"class\" column in the df_encoded DataFrame\n",
    "df_encoded['class'] = df_encoded['class'].apply(lambda x: 1 if x == 'p' else 0)\n",
    "\n",
    "# Convert the \"class\" column to a numeric data type (int)\n",
    "#df_encoded['class'] = pd.to_numeric(df['class'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to training and validation and Scale the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Data for training:\n",
    "X = df_encoded.drop(columns=['class']).values  # Features (excluding 'Type' column)\n",
    "y = df_encoded['class'].values  # Labels\n",
    "\n",
    "# Split Data into Training and Validation Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "print(type(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pytorch model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (7x117 and 9x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb Cell 16\u001b[0m line \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb Cell 16\u001b[0m line \u001b[0;36mGlassClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreaswergeland/git/ADA511/Datadrevne_sys/ML_project_fullPOP.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7x117 and 9x64)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and validation sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=7, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=7)\n",
    "\n",
    "# Build the Neural Network\n",
    "class GlassClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlassClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 64)\n",
    "        self.fc2 = nn.Linear(64, 90)\n",
    "        self.fc3 = nn.Linear(90, 64)\n",
    "        self.fc4 = nn.Linear(64, 6)  # 6 output units for 6 types\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = GlassClassifier()\n",
    "\n",
    "# Step 5: Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 6: Train the Model\n",
    "# Define a list to store training losses\n",
    "train_losses = []\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 200\n",
    "\n",
    "# Train the model and track the training loss\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate the Model\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[f'T{i}' for i in range(1, 8)],\n",
    "            yticklabels=[f'T{i}' for i in range(1, 8)])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "correct = sum(pred == label for pred, label in zip(all_preds, all_labels))\n",
    "accuracy = correct / len(all_labels)\n",
    "#print()\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = metoder.randomforest(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = metoder.gradientboost(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = metoder.linearregression(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = metoder.decisionregressor(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = metoder.mlpregression(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = metoder.supportvectoregressor(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = metoder.kneighborsregressor(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['KNN Regressor', 'Linear Regression', 'Decision Tree Regressor' ,'Random Forest Regressor',\n",
    " 'Gradient Boosting Regressor','Support Vector Regressor', 'MLP Regressor']\n",
    "tests_score = [KNN, lr, dr, rf, gb, svr, mlp]\n",
    "compare_models = pd.DataFrame({ \"Algorithms\": models, \"Tests Score\": tests_score })\n",
    "compare_models.sort_values(by = \"Tests Score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(x = \"Tests Score\", y = \"Algorithms\", data = compare_models)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
