{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import random\n",
    "import metoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['stakColorBelowRing'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vikto\\OneDrive - Høgskulen på Vestlandet\\Documents\\Programming\\Python codes\\datadriven_system\\Prosjekt_SOPP\\NormalAlgorithms\\ML_project_fullPOP.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vikto/OneDrive%20-%20H%C3%B8gskulen%20p%C3%A5%20Vestlandet/Documents/Programming/Python%20codes/datadriven_system/Prosjekt_SOPP/NormalAlgorithms/ML_project_fullPOP.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m drop_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcapSurface\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcapColor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39modor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgillSize\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgillColor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstalkColorAboveRing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstakColorBelowRing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msporePrintColor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpopulation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhabitat\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vikto/OneDrive%20-%20H%C3%B8gskulen%20p%C3%A5%20Vestlandet/Documents/Programming/Python%20codes/datadriven_system/Prosjekt_SOPP/NormalAlgorithms/ML_project_fullPOP.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m drop_list \u001b[39m=\u001b[39m drop_list \u001b[39m+\u001b[39m exstra_drop_list\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vikto/OneDrive%20-%20H%C3%B8gskulen%20p%C3%A5%20Vestlandet/Documents/Programming/Python%20codes/datadriven_system/Prosjekt_SOPP/NormalAlgorithms/ML_project_fullPOP.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m df_training \u001b[39m=\u001b[39m df_training\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49mdrop_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vikto/OneDrive%20-%20H%C3%B8gskulen%20p%C3%A5%20Vestlandet/Documents/Programming/Python%20codes/datadriven_system/Prosjekt_SOPP/NormalAlgorithms/ML_project_fullPOP.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39mdrop_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vikto/OneDrive%20-%20H%C3%B8gskulen%20p%C3%A5%20Vestlandet/Documents/Programming/Python%20codes/datadriven_system/Prosjekt_SOPP/NormalAlgorithms/ML_project_fullPOP.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df_total \u001b[39m=\u001b[39m df_total\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39mdrop_list)\n",
      "File \u001b[1;32mc:\\Users\\vikto\\OneDrive - Høgskulen på Vestlandet\\Documents\\Programming\\Python codes\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vikto\\OneDrive - Høgskulen på Vestlandet\\Documents\\Programming\\Python codes\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\vikto\\OneDrive - Høgskulen på Vestlandet\\Documents\\Programming\\Python codes\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vikto\\OneDrive - Høgskulen på Vestlandet\\Documents\\Programming\\Python codes\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6694\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6695\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6696\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6697\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6698\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['stakColorBelowRing'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#path:\n",
    "#file_path = r\"C:\\Users\\vikto\\Documents\\Skole\\Datadrevne_systemer\\ML_Project\\glass_data-4_lev.csv\"\n",
    "file_path_training = \"../Datasett/train_set.csv\"\n",
    "file_path_test = \"../Datasett/test_set.csv\"\n",
    "file_path_total_set =   \"../Datasett/mushrooms.csv\"\n",
    "#importing file and print how the structure of data were inported. \n",
    "df_training = pd.read_csv(file_path_training)\n",
    "df_test = pd.read_csv(file_path_test)\n",
    "df_total = pd.read_csv(file_path_total_set)\n",
    "\n",
    "exstra_drop_list = ['capSurface', 'gillSize', 'stalkRoot', 'capShape']\n",
    "drop_list = ['capSurface', 'capColor', 'odor', 'gillSize', 'gillColor', 'stalkColorAboveRing', 'stalkColorBelowRing', 'sporePrintColor', 'population', 'habitat']\n",
    "\n",
    "drop_list = drop_list + exstra_drop_list\n",
    "\n",
    "df_training = df_training.drop(columns=drop_list)\n",
    "df_test = df_test.drop(columns=drop_list)\n",
    "df_total = df_total.drop(columns=drop_list)\n",
    "\n",
    "\n",
    "#drop ID number\n",
    "#df = df.drop(columns=['Id'])\n",
    "\n",
    "print(df_test.__len__())\n",
    "df_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small exploration of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique rows in the DataFrame\n",
    "num_unique_rows = df_total.drop_duplicates().shape[0]\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique rows:\", num_unique_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set clearly shows that T1, T2 is most frequently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of age with hue for income\n",
    "#sns.histplot(data=df_total, x='capShape', hue='class', multiple='stack', palette='pastel')\n",
    "\n",
    "# Add labels and title\n",
    "#plt.xlabel('cap shape')\n",
    "#plt.ylabel('Frequency')\n",
    "#plt.title('cap shape Distribution by class')\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df.columns[:-1]:  # Exclude the 'Type' column\n",
    " #   sns.boxplot(x='Type', y=col, data=df)\n",
    "  #  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding to ensure the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for all categorical columns except the \"class\" column\n",
    "df_train_encoded = pd.get_dummies(df_training, columns=df_training.drop(columns=['class']).columns.tolist())[0:2000]\n",
    "df_test_encoded = pd.get_dummies(df_test, columns=df_test.drop(columns=['class']).columns.tolist())\n",
    "\n",
    "# Replace \"p\" with 1 and \"e\" with 0 in the \"class\" column in the df_training and df_test DataFrames\n",
    "df_train_encoded['class'] = df_train_encoded['class'].apply(lambda x: 1 if x == 'p' else 0)\n",
    "df_test_encoded['class'] = df_test_encoded['class'].apply(lambda x: 1 if x == 'p' else 0)\n",
    "\n",
    "# Splitting into features (X) and target variable (y)\n",
    "X_train, y_train = df_train_encoded.drop(['class'], axis=1), df_train_encoded['class']\n",
    "X_test, y_test = df_test_encoded.drop(['class'], axis=1), df_test_encoded['class']\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to training and validation and Scale the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model and get the training history\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# Plot the validation loss over epochs\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage as a dictionary\n",
    "results = {}\n",
    "\n",
    "#neural network:\n",
    "# Create confusion matrix and normalize it over predicted (columns)\n",
    "cm1 = sklm.confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy1= sklm.accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "results['neural network'] = {'accuracy': accuracy1, 'confusion_matrix': cm1}\n",
    "print(accuracy1, cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call each function and store the results\n",
    "accuracy2, cm2 = metoder.randomforest(X_train, X_test, y_train, y_test)\n",
    "results['random forrest'] = {'accuracy': accuracy2, 'confusion_matrix': cm2}\n",
    "print(accuracy2, cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3, cm3 = metoder.gradientboost(X_train, X_test, y_train, y_test)\n",
    "print(accuracy3, cm3)\n",
    "results['gradientboost'] = {'accuracy': accuracy3, 'confusion_matrix': cm3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy, confusion_matrix = metoder.linearregression(X_train, X_test, y_train, y_test)\n",
    "#results['linearregression'] = {'accuracy': accuracy, 'confusion_matrix': confusion_matrix}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy4, cm4= metoder.decisionregressor(X_train, X_test, y_train, y_test)\n",
    "results['decision tree classifier'] = {'accuracy': accuracy4, 'confusion_matrix':cm4}\n",
    "print(accuracy4, cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy, cm = metoder.mlpregression(X_train, X_test, y_train, y_test)\n",
    "#results['mlpregression'] = {'accuracy': accuracy, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy5, cm5 = metoder.supportvectorclassifier(X_train, X_test, y_train, y_test)\n",
    "results['supportvectoregressor'] = {'accuracy': accuracy5, 'confusion_matrix': cm5}\n",
    "print(accuracy5, cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy6, cm6 = metoder.kneighborsclassifier(X_train, X_test, y_train, y_test)\n",
    "results['kneighborsregressor'] = {'accuracy': accuracy6, 'confusion_matrix': cm6}\n",
    "print(accuracy6, cm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make tree lists of dictionary: \n",
    "algorithm_names = []\n",
    "accuracies = []\n",
    "confusion_matrices_list = []\n",
    "\n",
    "for algorithm, results_info in results.items():\n",
    "    algorithm_names.append(algorithm)\n",
    "    accuracies.append(results_info['accuracy'])\n",
    "    confusion_matrices_list.append(results_info['confusion_matrix'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models = pd.DataFrame({ \"Algorithms\": algorithm_names, \"accuracy\": accuracies})\n",
    "compare_models.sort_values(by = \"accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(x = \"accuracy\", y = \"Algorithms\", data = compare_models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Evaluation \n",
    "\n",
    "ulitity_matrix = np.array([[1.5, -2],\n",
    "                           [-0.2 , 0.7]])\n",
    "\n",
    "print()\n",
    "ulitity_score =[] \n",
    "\n",
    "for i in range(len(algorithm_names)):\n",
    "    ulitity_score.append(np.sum(np.array(confusion_matrices_list[i])*ulitity_matrix))\n",
    "    print(algorithm_names[i], \":\", confusion_matrices_list[i], \"utility score:\", ulitity_score[i])\n",
    "    \n",
    "\n",
    "compare_models = pd.DataFrame({ \"Algorithms\": algorithm_names, \"utility\": ulitity_score})\n",
    "compare_models.sort_values(by = \"utility\", ascending = False)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(x = \"utility\", y = \"Algorithms\", data = compare_models)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
